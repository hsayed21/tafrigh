{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8NgMnd42sOt"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "  <center>\n",
    "    <img src=\"https://user-images.githubusercontent.com/7662492/229289746-89c5a4c7-afa6-4d46-a0e6-63dfdeb98285.jpg\" width=\"250px\"/>\n",
    "\n",
    "  <h1>ØªÙØ±ÙŠØº - Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©</h1>\n",
    "  </center>\n",
    "\n",
    "  <p>Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ ÙÙŠ ØªÙØ±ÙŠØº Ù„ØªÙØ±ÙŠØº Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ§Ù„Ù…Ø±Ø¦ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙØ±ÙŠØº:</p>\n",
    "\n",
    "  <ol>\n",
    "    <li>Ù‚Ù… Ø¨Ø¥Ø¯Ø®Ø§Ù„ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù…Ù† Ù…Ù†ØµØ© YouTube Ø£Ùˆ Ø£ÙŠ Ù…Ù†ØµØ© Ø£Ø®Ø±Ù‰ ÙÙŠ Ø­Ù‚Ù„ \"urls\" ÙˆØªØ£ÙƒØ¯ Ù…Ù† ÙØµÙ„Ù‡Ø§ Ø¨Ù…Ø³Ø§ÙØ©ØŒ Ø£Ùˆ Ù‚Ù… Ø¨ØªØ±Ùƒ Ø§Ù„Ø­Ù‚Ù„ ÙØ§Ø±ØºÙ‹Ø§ Ù„ØªÙØ±ÙŠØº Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙŠ Ù‚Ù…Øª Ø¨Ø±ÙØ¹Ù‡Ø§</li>\n",
    "    <li>(Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù‚Ù… Ø¨ØªØ­Ø¯ÙŠØ¯ Ø£Ù‚Ù„ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ ÙƒÙ„ Ø¬Ø²Ø¡ Ù…Ù† Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØªÙØ±ÙŠØº. ÙŠØ¤Ø«Ø± Ù‡Ø°Ø§ ÙÙŠ Ø·ÙˆÙ„ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… ØªÙØ±ÙŠØºÙ‡Ø§</li>\n",
    "    <li>\n",
    "      Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ù†Ù…Ø§Ø°Ø¬ Whisper:\n",
    "      <ul>\n",
    "        <li>Ù‚Ù… Ø¨Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ±Ø§Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ Ø­Ù‚Ù„ \"model\"</li>\n",
    "        <li>Ù‚Ù… Ø¨Ø§Ø®ØªÙŠØ§Ø± Ù„ØºØ© Ø§Ù„Ù…Ø§Ø¯Ø© ÙÙŠ Ø­Ù‚Ù„ \"language\"</li>\n",
    "        <li>Ù‚Ù… Ø¨Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…ÙØ±Ø§Ø¯ Ø¥Ù†Ø¬Ø§Ø²Ù‡Ø§ ÙÙŠ Ø­Ù‚Ù„ \"task\" Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª ØªÙØ±ÙŠØº Ø§Ù„Ù…Ø§Ø¯Ø© Ø£Ùˆ ØªØ±Ø¬Ù…ØªÙ‡Ø§ Ù„Ù„Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠØ©</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "      Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ© wit.ai:\n",
    "      <ul>\n",
    "        <li>Ù‚Ù… Ø¨ÙˆØ¶Ø¹ Ù…ÙØªØ§Ø­ wit.ai Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙÙŠ Ø­Ù‚Ù„ \"wit_api_key\"</li>\n",
    "        <li>(Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù‚Ù… Ø¨ØªØ­Ø¯ÙŠØ¯ Ø£Ù‚ØµÙ‰ Ù…Ø¯Ø© Ù„Ù„ØªÙ‚Ø·ÙŠØ¹ ÙˆØ§Ù„ØªÙŠ Ø³ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ø¬Ù…Ù„ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„ Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„Ù…Ø­ØªÙˆÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù‡Ù…</li>\n",
    "  </ol>\n",
    "\n",
    "  <p>ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ø±Ø¨Ø© Ø§Ù„ØªÙØ±ÙŠØº Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Whisper ÙˆØªÙ‚Ù†ÙŠØ© wit.ai ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙØ±ÙŠØº Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ø­Ø§Ù„ØªÙƒ. ÙƒÙ…Ù„Ø§Ø­Ø¸Ø© Ø¹Ø§Ù…Ø©ØŒ Ù†Ù…Ø§Ø°Ø¬ Whisper ØªÙ‚ÙˆÙ… Ø¨ØªÙØ±ÙŠØº Ø§Ù„Ù‡Ù…Ø²Ø§Øª ÙˆØ§Ù„ØªØ´ÙƒÙŠÙ„Ø§Øª ÙˆØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ Ù…Ù† wit.aiØŒ Ù„ÙƒÙ† wit.ai ÙŠÙÙ†ØªØ¬ Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© Ø£Ù‚Ù„.</p>\n",
    "\n",
    "  <p>Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø³ÙŠØªÙ… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙŠØ© Ø¨Ø´ÙƒÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨ØµÙŠØºØ© <code>txt</code> Ùˆ <code>srt</code> ÙˆØ³ÙŠÙƒÙˆÙ† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ Ù…ÙØ¹Ø±Ù‘Ù Ø§Ù„Ù…Ø§Ø¯Ø© Ø¹Ù„Ù‰ Ù…Ù†ØµØ© YouTube Ø§Ù„Ø°ÙŠ ÙŠÙƒÙˆÙ† ÙÙŠ Ø¢Ø®Ø± Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø§Ø¯Ø©: https://youtu.be/<strong>4h5P7jXvW98</strong>.</p>\n",
    "\n",
    "  <hr>\n",
    "\n",
    "  <p>ÙŠÙ…ÙƒÙ†Ùƒ Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ø´Ø±ÙˆØ¹ <strong>Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©</strong> ÙˆØ§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ Ù…Ù† Ø®Ù„Ø§Ù„:</p>\n",
    "\n",
    "  <ul>\n",
    "    <li><a href=\"https://t.me/ieasybooks\">Ù‚Ù†Ø§ØªÙ†Ø§ Ø¹Ù„Ù‰ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…</a></li>\n",
    "    <li><a href=\"https://www.youtube.com/@ieasybooks\">Ù‚Ù†Ø§ØªÙ†Ø§ Ø¹Ù„Ù‰ ÙŠÙˆØªÙŠÙˆØ¨</a></li>\n",
    "    <li><a href=\"https://twitter.com/iieasybooks\">Ø­Ø³Ø§Ø¨Ù†Ø§ Ø¹Ù„Ù‰ ØªÙˆÙŠØªØ±</a></li>\n",
    "    <li><a href=\"https://www.facebook.com/ieasybooks\">ØµÙØ­ØªÙ†Ø§ Ø¹Ù„Ù‰ ÙÙŠØ³Ø¨ÙˆÙƒ</a></li>\n",
    "    <li><a href=\"https://github.com/ieasybooks\">Ø­Ø³Ø§Ø¨Ù†Ø§ Ø¹Ù„Ù‰ GitHub (Ù„Ù„Ù…Ø¨Ø±Ù…Ø¬ÙŠÙ†)</a></li>\n",
    "    <li>Ø¨Ø±ÙŠØ¯Ù†Ø§ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: easybooksdev@gmail.com</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY05i198xi3D"
   },
   "outputs": [],
   "source": [
    "# @title <h1><center>ØªÙØ±ÙŠØº</center></h1>\n",
    "\n",
    "print('Ø¬Ø§Ø±Ù ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…Ù„.')\n",
    "\n",
    "# Setup Tafrigh.\n",
    "!apt-get install -q portaudio19-dev python3-pyaudio > pyaudio_fix_logs.txt\n",
    "%pip install -U tafrigh[wit,whisper]==1.7.6 > install_logs.txt\n",
    "%pip install -U yt-dlp[\"default\"] > update_yt_dlp_logs.txt\n",
    "\n",
    "# Start: Quick fix related to Colab, HuggingFace, and faster-whisper.\n",
    "!apt install libcublas11 > fix_logs.txt\n",
    "!pip install ctranslate2==4.5.0 > ctranslate2_downgrade_logs.txt\n",
    "\n",
    "!apt install nodejs -y\n",
    "\n",
    "from huggingface_hub.utils import _runtime\n",
    "_runtime._is_google_colab = False\n",
    "# End: Quick fix related to Colab, HuggingFace, and faster-whisper.\n",
    "\n",
    "# Get inputs.\n",
    "\n",
    "# @markdown <h1 dir=\"rtl\">Ù…Ø¯Ø®Ù„Ø§Øª Ø¹Ø§Ù…Ø©</h1>\n",
    "\n",
    "# @markdown <p dir=\"rtl\">Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªÙØ±ÙŠØºÙ‡Ø§ ÙˆØªØ£ÙƒØ¯ Ù…Ù† ÙØµÙ„Ù‡Ø§ Ø¨Ù…Ø³Ø§ÙØ©ØŒ Ø£Ùˆ Ù‚Ù… Ø¨ØªØ±Ùƒ Ø§Ù„Ø­Ù‚Ù„ ÙØ§Ø±ØºÙ‹Ø§ Ù„ØªÙØ±ÙŠØº Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙŠ Ù‚Ù…Øª Ø¨Ø±ÙØ¹Ù‡Ø§</p>\n",
    "urls = 'https://www.youtube.com/playlist?list=PLSSxr3Rf2_X2oKwiy4UhzIdj4ACzB6dee'  # @param { type: \"string\" }\n",
    "\n",
    "# @markdown <p dir=\"rtl\">Ø£Ù‚Ù„ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ ÙƒÙ„ Ø¬Ø²Ø¡ Ù…Ù† Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØªÙØ±ÙŠØº</p>\n",
    "min_words_per_segment = 1  # @param {type:\"slider\", min:1, max:100, step:1}\n",
    "\n",
    "# @markdown <p dir=\"rtl\">ØµÙŠØºØ© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©</p>\n",
    "output_format = \"TXT ÙÙ‚Ø·\"  # @param [\"TXT ÙÙ‚Ø·\", \"SRT ÙÙ‚Ø·\", \"TXT Ùˆ SRT\"]\n",
    "\n",
    "# @markdown ---\n",
    "\n",
    "# @markdown <h1 dir=\"rtl\">Ù…Ø¯Ø®Ù„Ø§Øª Ø®Ø§ØµØ© Ø¨Ù†Ù…Ø§Ø°Ø¬ Whisper</h1>\n",
    "\n",
    "# @markdown <p dir=\"rtl\">Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ±Ø§Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„ØªÙØ±ÙŠØº</p>\n",
    "model = 'large-v3 (Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©)'  # @param [\"large-v3 (Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©)\", \"medium\", \"base\", \"small\", \"tiny (Ø£Ù‚Ù„ Ø¯Ù‚Ø©)\"]\n",
    "\n",
    "# @markdown <p dir=\"rtl\">(Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù„ØºØ© Ø§Ù„Ù…Ø§Ø¯Ø©</p>\n",
    "language = 'ar'  # @param [\"ar\", \"af\", \"am\", \"as\", \"az\", \"ba\", \"be\", \"bg\", \"bn\", \"bo\", \"br\", \"bs\", \"ca\", \"cs\", \"cy\", \"da\", \"de\", \"el\", \"en\", \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fo\", \"fr\", \"gl\", \"gu\", \"ha\", \"haw\", \"he\", \"hi\", \"hr\", \"ht\", \"hu\", \"hy\", \"id\", \"is\", \"it\", \"ja\", \"jw\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"la\", \"lb\", \"ln\", \"lo\", \"lt\", \"lv\", \"mg\", \"mi\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"mt\", \"my\", \"ne\", \"nl\", \"nn\", \"no\", \"oc\", \"pa\", \"pl\", \"ps\", \"pt\", \"ro\", \"ru\", \"sa\", \"sd\", \"si\", \"sk\", \"sl\", \"sn\", \"so\", \"sq\", \"sr\", \"su\", \"sv\", \"sw\", \"ta\", \"te\", \"tg\", \"th\", \"tk\", \"tl\", \"tr\", \"tt\", \"uk\", \"ur\", \"uz\", \"vi\", \"yi\", \"yo\", \"zh\"]\n",
    "\n",
    "# @markdown <p dir=\"rtl\">(Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø§Ù„Ù…Ù‡Ù…Ø©</p>\n",
    "task = 'ØªÙØ±ÙŠØº'  # @param [\"ØªÙØ±ÙŠØº\", \"ØªØ±Ø¬Ù…Ø©\"]\n",
    "\n",
    "# @markdown ---\n",
    "\n",
    "# @markdown <h1 dir=\"rtl\">Ù…Ø¯Ø®Ù„Ø§Øª Ø®Ø§ØµØ© Ø¨ØªÙ‚Ù†ÙŠØ© wit.ai</h1>\n",
    "\n",
    "# @markdown <p dir=\"rtl\">Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¹Ù„Ù‰ Ù…ÙˆÙ‚Ø¹ wit.ai</p>\n",
    "wit_api_key = ''  # @param { type: \"string\" }\n",
    "\n",
    "# @markdown <p dir=\"rtl\">(Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø£Ù‚ØµÙ‰ Ù…Ø¯Ø© Ù„Ù„ØªÙ‚Ø·ÙŠØ¹ ÙˆØ§Ù„ØªÙŠ Ø³ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ø¬Ù…Ù„ ÙÙŠ Ù…Ù„Ù SRT</p>\n",
    "max_cutting_duration = 15  # @param {type:\"slider\", min:1, max:17, step:1}\n",
    "\n",
    "# @markdown ---\n",
    "\n",
    "# @markdown <h1 dir=\"rtl\">Ø®ÙŠØ§Ø±Ø§Øª Google Drive</h1>\n",
    "\n",
    "# @markdown <p dir=\"rtl\">Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¹Ù„Ù‰ Google Drive (Ù…ÙˆØµÙ‰ Ø¨Ù‡ Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)</p>\n",
    "use_google_drive = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# @markdown <p dir=\"rtl\">Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¹Ù„Ù‰ Google Drive</p>\n",
    "drive_folder_name = \"Tafrigh_Transcripts\"  # @param {type:\"string\"}\n",
    "\n",
    "if model == 'large-v3 (Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©)':\n",
    "    model = 'large-v3'\n",
    "elif model == 'tiny (Ø£Ù‚Ù„ Ø¯Ù‚Ø©)':\n",
    "    model = 'tiny'\n",
    "\n",
    "if task == 'ØªÙØ±ÙŠØº':\n",
    "  task = 'transcribe'\n",
    "elif task == 'ØªØ±Ø¬Ù…Ø©':\n",
    "  task = 'translate'\n",
    "\n",
    "# Parse output format\n",
    "output_formats = []\n",
    "if output_format == \"TXT ÙÙ‚Ø·\":\n",
    "    output_formats = ['txt']\n",
    "elif output_format == \"SRT ÙÙ‚Ø·\":\n",
    "    output_formats = ['srt']\n",
    "else:  # \"TXT Ùˆ SRT\"\n",
    "    output_formats = ['txt', 'srt']\n",
    "\n",
    "# Imports.\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import yt_dlp\n",
    "import shutil\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "from google.colab import files\n",
    "from tafrigh import farrigh, Config\n",
    "\n",
    "# --- Mount Google Drive if enabled ---\n",
    "drive_output_dir = None\n",
    "if use_google_drive:\n",
    "    print('ğŸ“ Ø¬Ø§Ø±Ù Ø±Ø¨Ø· Google Drive...')\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Create output folder in Drive with timestamp to avoid conflicts\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    drive_output_dir = f\"/content/drive/MyDrive/{drive_folder_name}\"\n",
    "    if not os.path.exists(drive_output_dir):\n",
    "        os.makedirs(drive_output_dir, exist_ok=True)\n",
    "        print(f'âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø¹Ù„Ù‰ Drive: {drive_folder_name}')\n",
    "    print(f'ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø±: {drive_output_dir}\\n')\n",
    "\n",
    "# Setup local directories.\n",
    "output_dir = 'output'\n",
    "if not os.path.exists(output_dir):\n",
    "  os.mkdir(output_dir)\n",
    "else:\n",
    "  # Clean up before start\n",
    "  shutil.rmtree(output_dir)\n",
    "  os.mkdir(output_dir)\n",
    "\n",
    "# --- Cookies auto-detection ---\n",
    "COOKIES_FILE = \"cookies.txt\"\n",
    "USE_COOKIES = os.path.exists(COOKIES_FILE)\n",
    "\n",
    "# --- Start: Fetch video titles ---\n",
    "print('Ø¬Ø§Ø±Ù Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ).')\n",
    "\n",
    "ydl_opts = {\n",
    "    'quiet': True,\n",
    "    'no_warnings': True,\n",
    "    'extract_flat': 'in_playlist',\n",
    "    'extractor_args': {\n",
    "        'youtube': {\n",
    "            'player_client': ['android', 'web'],\n",
    "            'skip': ['hls', 'dash']\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Use cookies if exist\n",
    "if USE_COOKIES:\n",
    "    print('Ø§Ù„Ù…Ù„Ù cookies.txt Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø¬Ø§Ø±Ù Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡.')\n",
    "    ydl_opts.update({\n",
    "        'cookies': 'cookies.txt',\n",
    "        'js_runtime': 'node',\n",
    "    })\n",
    "else:\n",
    "    print('Ø§Ù„Ù…Ù„Ù cookies.txt ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø³ÙŠØªÙ… Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¨Ø¯ÙˆÙ†Ù‡.')\n",
    "\n",
    "urls_list = [u.strip() for u in urls.split(' ') if u.strip()]\n",
    "video_titles = {}\n",
    "for url in urls_list:\n",
    "  try:\n",
    "      with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "          info_dict = ydl.extract_info(url, download=False)\n",
    "          if info_dict:\n",
    "              # Check if it's a playlist\n",
    "              if info_dict.get('_type') == 'playlist':\n",
    "                  print(f\"âœ“ Ø§ÙƒØªØ´Ø§Ù Ù‚Ø§Ø¦Ù…Ø© ØªØ´ØºÙŠÙ„: {info_dict.get('title', 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†')}\")\n",
    "                  entries = info_dict.get('entries', [])\n",
    "                  print(f\"  Ø¹Ø¯Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª: {len(entries)}\")\n",
    "\n",
    "                  for entry in entries:\n",
    "                      if entry:\n",
    "                          video_id = entry.get('id')\n",
    "                          video_title = entry.get('title')\n",
    "                          if video_id and video_title:\n",
    "                              video_titles[video_id] = video_title\n",
    "                              print(f\"  âœ“ {video_title}\")\n",
    "              else:\n",
    "                  # Single video\n",
    "                  video_id = info_dict.get('id')\n",
    "                  video_title = info_dict.get('title')\n",
    "                  if video_id and video_title:\n",
    "                      video_titles[video_id] = video_title\n",
    "                      print(f\"âœ“ ØªÙ… Ø¬Ù„Ø¨ Ø¹Ù†ÙˆØ§Ù†: {video_title}\")\n",
    "                  else:\n",
    "                      print(f\"âš  ØªØ¹Ø°Ø± Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§Ù…Ù„Ø© Ù„Ù„ÙÙŠØ¯ÙŠÙˆ\")\n",
    "  except Exception as e:\n",
    "      print(f\"âš  ØªØ­Ø°ÙŠØ±: ØªØ¹Ø°Ø± Ø¬Ù„Ø¨ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ\")\n",
    "      print(f\"   Ø§Ù„Ø®Ø·Ø£: {str(e)[:100]}\")\n",
    "      print(f\"   Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø±Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙƒØ§Ø³Ù… Ù„Ù„Ù…Ù„Ù\")\n",
    "\n",
    "print(f'\\nâœ“ ØªÙ… Ø¬Ù„Ø¨ {len(video_titles)} Ø¹Ù†ÙˆØ§Ù† Ø¨Ù†Ø¬Ø§Ø­.\\n')\n",
    "\n",
    "# Start Tafrigh.\n",
    "if wit_api_key:\n",
    "  print('Ø¬Ø§Ø±Ù ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø¥Ù„Ù‰ Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª wit.ai.')\n",
    "else:\n",
    "  print('Ø¬Ø§Ø±Ù ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø¥Ù„Ù‰ Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Whisper.')\n",
    "\n",
    "config = Config(\n",
    "  input=Config.Input(\n",
    "    urls_or_paths=urls_list if urls_list else ['.'],\n",
    "    skip_if_output_exist=False,\n",
    "    download_retries=3,\n",
    "    yt_dlp_options=(\n",
    "      '''\n",
    "      {\n",
    "        \"cookies\": \"cookies.txt\",\n",
    "        \"js_runtime\": \"node\"\n",
    "      }\n",
    "      ''' if USE_COOKIES else '{}'\n",
    "    ),\n",
    "    verbose=False,\n",
    "  ),\n",
    "  whisper=Config.Whisper(\n",
    "    model_name_or_path=model,\n",
    "    task=task,\n",
    "    language=language,\n",
    "    use_faster_whisper=True,\n",
    "    beam_size=5,\n",
    "    ct2_compute_type='default',\n",
    "  ),\n",
    "  wit=Config.Wit(\n",
    "    wit_client_access_tokens=None if len(wit_api_key.strip()) == 0 else wit_api_key.split(),\n",
    "    max_cutting_duration=max_cutting_duration,\n",
    "  ),\n",
    "  output=Config.Output(\n",
    "    min_words_per_segment=min_words_per_segment,\n",
    "    save_files_before_compact=False,\n",
    "    save_yt_dlp_responses=False,\n",
    "    output_sample=0,\n",
    "    output_formats=output_formats,\n",
    "    output_dir=output_dir,\n",
    "  ),\n",
    ")\n",
    "\n",
    "def get_output_files():\n",
    "    \"\"\"Get set of current output files (excluding archive.txt and mp3 files).\"\"\"\n",
    "    extensions = []\n",
    "    if 'txt' in output_formats:\n",
    "        extensions.append(f\"{output_dir}/*.txt\")\n",
    "    if 'srt' in output_formats:\n",
    "        extensions.append(f\"{output_dir}/*.srt\")\n",
    "\n",
    "    all_files = set()\n",
    "    for ext_pattern in extensions:\n",
    "        all_files.update(glob.glob(ext_pattern))\n",
    "\n",
    "    archive_path = os.path.join(output_dir, 'archive.txt')\n",
    "    return {f for f in all_files if f != archive_path}\n",
    "\n",
    "def copy_files_to_drive(new_files, video_titles, drive_output_dir, video_number):\n",
    "    \"\"\"Rename files and copy to Google Drive.\"\"\"\n",
    "    if not new_files or not drive_output_dir:\n",
    "        return []\n",
    "\n",
    "    copied_files = []\n",
    "    video_title = None\n",
    "\n",
    "    for file_path in new_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        base, ext = os.path.splitext(file_name)\n",
    "\n",
    "        # Determine new name\n",
    "        if base in video_titles:\n",
    "            title = video_titles[base]\n",
    "            video_title = title\n",
    "            safe_title = re.sub(r'[\\\\/:*?\"<>|.]', '', title).strip()\n",
    "            if safe_title:\n",
    "                new_name = f\"{safe_title}{ext}\"\n",
    "            else:\n",
    "                new_name = file_name\n",
    "        else:\n",
    "            new_name = file_name\n",
    "\n",
    "        # Handle duplicate names\n",
    "        drive_path = os.path.join(drive_output_dir, new_name)\n",
    "        counter = 1\n",
    "        base_name, ext = os.path.splitext(new_name)\n",
    "        while os.path.exists(drive_path):\n",
    "            drive_path = os.path.join(drive_output_dir, f\"{base_name}_{counter}{ext}\")\n",
    "            counter += 1\n",
    "\n",
    "        try:\n",
    "            shutil.copy2(file_path, drive_path)\n",
    "            copied_files.append(drive_path)\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Ø®Ø·Ø£ ÙÙŠ Ù†Ø³Ø® Ø§Ù„Ù…Ù„Ù: {e}\")\n",
    "\n",
    "    return copied_files\n",
    "\n",
    "# Track progress and save after each video\n",
    "if use_google_drive:\n",
    "    print(\"â³ Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª (Ø³ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¹Ù„Ù‰ Google Drive Ø¨Ø¹Ø¯ ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ)...\\n\")\n",
    "else:\n",
    "    print(\"â³ Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª...\\n\")\n",
    "\n",
    "last_video_key = None\n",
    "video_count = 0\n",
    "completed_videos = set()\n",
    "known_files = get_output_files()\n",
    "all_drive_files = []\n",
    "\n",
    "try:\n",
    "    for item in farrigh(config):\n",
    "        progress_info = item if isinstance(item, dict) else (item[0] if isinstance(item, tuple) else {})\n",
    "\n",
    "        inner_current = progress_info.get('inner_current', 0)\n",
    "        outer_current = progress_info.get('outer_current', 0)\n",
    "        inner_status = progress_info.get('inner_status', '')\n",
    "        inner_total = progress_info.get('inner_total', 0)\n",
    "\n",
    "        current_video_key = (outer_current, inner_current)\n",
    "\n",
    "        # Show progress when starting a new video\n",
    "        if current_video_key != last_video_key and inner_current > 0:\n",
    "            if inner_total > 0:\n",
    "                print(f\"ğŸ“¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ {inner_current}/{inner_total}...\")\n",
    "            last_video_key = current_video_key\n",
    "\n",
    "        # When video completed, save files immediately\n",
    "        if inner_status == 'completed' and current_video_key not in completed_videos:\n",
    "            completed_videos.add(current_video_key)\n",
    "            video_count += 1\n",
    "\n",
    "            # Get new files for this video\n",
    "            current_files = get_output_files()\n",
    "            new_files = current_files - known_files\n",
    "\n",
    "            if new_files:\n",
    "                print(f\"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ {video_count}/{inner_total if inner_total > 0 else '?'}\")\n",
    "\n",
    "                if use_google_drive and drive_output_dir:\n",
    "                    # Copy to Google Drive\n",
    "                    copied = copy_files_to_drive(new_files, video_titles, drive_output_dir, video_count)\n",
    "                    all_drive_files.extend(copied)\n",
    "\n",
    "                    if copied:\n",
    "                        file_names = [os.path.basename(f) for f in copied]\n",
    "                        print(f\"   \udcbe ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¹Ù„Ù‰ Drive: {', '.join(file_names)}\\n\")\n",
    "\n",
    "            known_files = current_files\n",
    "\n",
    "    print('\\nâœ… Ø§ÙƒØªÙ…Ù„ ØªÙØ±ÙŠØº Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª!')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Ø§Ù„ØªÙØ±ÙŠØº ÙØ´Ù„: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "    if use_google_drive and drive_output_dir:\n",
    "        print(f\"\\nâš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰ Google Drive:\")\n",
    "        print(f\"   ğŸ“ {drive_output_dir}\")\n",
    "\n",
    "# Final: Create ZIP and download\n",
    "if use_google_drive and drive_output_dir:\n",
    "    # Check what files are in Drive folder\n",
    "    drive_files = []\n",
    "    if 'txt' in output_formats:\n",
    "        drive_files.extend(glob.glob(f\"{drive_output_dir}/*.txt\"))\n",
    "    if 'srt' in output_formats:\n",
    "        drive_files.extend(glob.glob(f\"{drive_output_dir}/*.srt\"))\n",
    "\n",
    "    if drive_files:\n",
    "        print(f'\\nğŸ“ ØªÙ… Ø­ÙØ¸ {len(drive_files)} Ù…Ù„ÙØ§Øª Ø¹Ù„Ù‰ Google Drive')\n",
    "        print(f'   Ø§Ù„Ù…Ø³Ø§Ø±: {drive_output_dir}')\n",
    "\n",
    "        # Create final ZIP in Drive\n",
    "        zip_name = os.path.basename(drive_output_dir) + \".zip\"\n",
    "        zip_path = os.path.join(os.path.dirname(drive_output_dir), zip_name)\n",
    "\n",
    "        print(f'\\nğŸ“¦ Ø¬Ø§Ø±Ù Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP...')\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for file_path in drive_files:\n",
    "                zipf.write(file_path, os.path.basename(file_path))\n",
    "\n",
    "        print(f'âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡: {zip_name}')\n",
    "        print(f'   Ø§Ù„Ù…Ø³Ø§Ø±: {zip_path}')\n",
    "\n",
    "        # Try to download\n",
    "        print(f'\\nğŸ“¥ Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ZIP...')\n",
    "        try:\n",
    "            files.download(zip_path)\n",
    "            print(f'âœ… ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù…ÙŠÙ„!')\n",
    "        except Exception as e:\n",
    "            print(f'âš  ØªØ¹Ø°Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: {e}')\n",
    "            print(f'\\nğŸ“Œ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù…Ù† Google Drive:')\n",
    "            print(f'   ğŸ“ Ø§Ù„Ù…Ø¬Ù„Ø¯: {drive_output_dir}')\n",
    "            print(f'   ğŸ“¦ Ù…Ù„Ù ZIP: {zip_path}')\n",
    "\n",
    "    else:\n",
    "        print('\\nâš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ù„Ù„ØªØ­Ù…ÙŠÙ„')\n",
    "\n",
    "else:\n",
    "    # No Google Drive - download directly\n",
    "    print('\\nØ¬Ø§Ø±Ù Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ù…Ù„ÙØ§Øª...')\n",
    "\n",
    "    generated_files = []\n",
    "    if 'txt' in output_formats:\n",
    "        generated_files.extend(glob.glob(f\"{output_dir}/*.txt\"))\n",
    "    if 'srt' in output_formats:\n",
    "        generated_files.extend(glob.glob(f\"{output_dir}/*.srt\"))\n",
    "\n",
    "    for file_path in generated_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        base, ext = os.path.splitext(file_name)\n",
    "\n",
    "        if base in video_titles:\n",
    "            title = video_titles[base]\n",
    "            safe_title = re.sub(r'[\\\\/:*?\"<>|.]', '', title).strip()\n",
    "\n",
    "            if not safe_title:\n",
    "                continue\n",
    "\n",
    "            new_path = os.path.join(output_dir, f\"{safe_title}{ext}\")\n",
    "\n",
    "            counter = 1\n",
    "            while os.path.exists(new_path):\n",
    "                new_path = os.path.join(output_dir, f\"{safe_title}_{counter}{ext}\")\n",
    "                counter += 1\n",
    "\n",
    "            os.rename(file_path, new_path)\n",
    "\n",
    "    # Download all files\n",
    "    print('Ø¬Ø§Ø±Ù ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙŠØ©.')\n",
    "\n",
    "    final_files = []\n",
    "    if 'txt' in output_formats:\n",
    "        final_files.extend(glob.glob(f\"{output_dir}/*.txt\"))\n",
    "    if 'srt' in output_formats:\n",
    "        final_files.extend(glob.glob(f\"{output_dir}/*.srt\"))\n",
    "\n",
    "    archive_path = os.path.join(output_dir, 'archive.txt')\n",
    "    all_files = [f for f in final_files if f != archive_path]\n",
    "\n",
    "    if len(all_files) > 4:\n",
    "        # Create ZIP for many files\n",
    "        print(f\"ğŸ“¦ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª ({len(all_files)}) - Ø¬Ø§Ø±Ù Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP...\")\n",
    "\n",
    "        zip_path = os.path.join(output_dir, 'all_transcripts.zip')\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for file_path in all_files:\n",
    "                zipf.write(file_path, os.path.basename(file_path))\n",
    "\n",
    "        print(f\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡: all_transcripts.zip\")\n",
    "        files.download(zip_path)\n",
    "        print(f\"âœ… ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù…ÙŠÙ„: all_transcripts.zip\")\n",
    "\n",
    "    else:\n",
    "        # Download files individually\n",
    "        for file_path in all_files:\n",
    "            files.download(file_path)\n",
    "\n",
    "print('\\nğŸ‰ Ø§Ù†ØªÙ‡Ù‰!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
